from textblob import TextBlob
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from transformers import pipeline
from openai import OpenAI
import os
from dotenv import load_dotenv  # Install with: pip install python-dotenv

load_dotenv()  # âœ… Load environment variables from .env file

api_key = os.getenv("OPENAI_API_KEY")  

client = OpenAI(api_key=api_key)
# åˆå§‹åŒ– VADER
analyzer = SentimentIntensityAnalyzer()

def analyze_sentiment(text: str):
    """ä½¿ç”¨ VADER & TextBlob é€²è¡Œæƒ…æ„Ÿåˆ†æ"""
    vader_score = analyzer.polarity_scores(text)["compound"]
    blob_score = TextBlob(text).sentiment.polarity
    sentiment = "Positive" if vader_score > 0.05 else "Negative" if vader_score < -0.05 else "Neutral"
    return {"sentiment": sentiment, "vader_score": vader_score, "blob_score": blob_score}

# è¼‰å…¥ Hugging Face é è¨“ç·´çš„å¿ƒç†åˆ†æ NLP æ¨¡å‹
psychology_model = pipeline("text-classification", model="bhadresh-savani/distilbert-base-uncased-emotion", return_all_scores=True)
# ä½¿ç”¨ Hugging Face é è¨“ç·´çš„ NLP pipeline ä¾†åˆ†ææƒ…ç·’
emotion_analyzer = pipeline("text-classification", model="bhadresh-savani/bert-base-uncased-emotion", return_all_scores=True)

def analyze_psychology(text: str):
    """å¿ƒç†åˆ†æ NLP æ¨¡å‹"""
    # å–å¾—æƒ…ç·’åˆ†æ•¸
    emotion_scores = emotion_analyzer(text)[0]

    # å°‡æƒ…ç·’åˆ†æ•¸è½‰æ›æˆ JSON æ ¼å¼
    emotions = {entry['label']: entry['score'] for entry in emotion_scores}

    # âœ…ã€å®Œæ•´å¿ƒç†åˆ†ææŒ‡æ¨™ï¼Œç¢ºä¿æ‰€æœ‰æŒ‡æ¨™éƒ½æœ‰å€¼ã€‘âœ…
    psychology_factors = {
        "Anxiety": round((emotions.get("fear", 0) + emotions.get("sadness", 0.1)) * 100, 1),
        "Confidence": round(max(emotions.get("joy", 0), 0.5) * 100, 1),
        "Overthinking": round(emotions.get("fear", 0) * 100, 1),
        "Self-Doubt": round(emotions.get("anger", 0) * 100, 1),
        "Social Avoidance": round((emotions.get("sadness", 0.1) + emotions.get("fear", 0.2)) * 100, 1),
        "Aggression": round(emotions.get("anger", 0) * 100, 1)
    }

    # âœ…ã€ç¢ºä¿æ‰€æœ‰å¿ƒç†æŒ‡æ¨™å³ä½¿æ˜¯ 0 ä¹Ÿæœƒè¿”å›ï¼ã€‘âœ…
    for key in psychology_factors:
        if key not in psychology_factors:
            psychology_factors[key] = 0

    # é¸æ“‡æœ€é«˜çš„å¿ƒç†ç‹€æ…‹
    primary_psychology_state = max(psychology_factors, key=psychology_factors.get)

    return {
        "state": primary_psychology_state,
        "confidence": psychology_factors[primary_psychology_state],
        "emotion_scores": emotions,
        "psychology_factors": psychology_factors
    }


def generate_next_question(state: str, history: list, deep_dive: bool = False):
    """ç”Ÿæˆå¿ƒç†åˆ†æé—®é¢˜ï¼Œæ”¯æŒã€Œæ·±å…¥çœŸç›¸æ¨¡å¼ã€ï¼Œæ­éœ²éšè—å¿ƒç†åŠ¨æœº"""

    MAX_ROUNDS = 3  # è¨­å®šæœ€å¤§å°è©±è¼ªæ•¸
    current_round = len(history)

    if deep_dive:
        # **ğŸ”¥ã€Œæ·±å…¥çœŸç›¸æ¨¡å¼ã€- è§£æå°æ–¹è¡Œç‚ºèƒŒå¾Œçš„å¿ƒç†å‹•æ©Ÿ**
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½å¿ƒç†å­¸å°ˆå®¶ï¼Œæ“…é•·åˆ†æäººéš›é—œä¿‚èˆ‡æ·±å±¤å¿ƒç†å‹•æ©Ÿã€‚"
                                          "è«‹æ ¹æ“šä½¿ç”¨è€…çš„ç¶“æ­·ï¼Œå›ç­”ï¼š**ç‚ºä»€éº¼å°æ–¹æœƒé€™æ¨£å°å¾…ä»–ï¼Ÿ**"
                                          "ä¸è¦æä¾›æº«å’Œçš„å®‰æ…°ï¼Œè€Œæ˜¯ç›´æ“Šæ ¸å¿ƒï¼Œæ­éœ²å°æ–¹çš„å¿ƒç†æ©Ÿåˆ¶èˆ‡è¡Œç‚ºå‹•æ©Ÿã€‚"
                                          "è«‹ç¢ºä¿å…§å®¹ç›´æ¥ã€éŠ³åˆ©ï¼Œä¸¦ä¸”æä¾›å¯ä»¥æ”¹è®Šä½¿ç”¨è€…åƒ¹å€¼è§€çš„é—œéµå»ºè­°ã€‚"},
            {"role": "user", "content": f"ç•¶å‰ä½¿ç”¨è€…çš„æƒ…ç·’æ˜¯ {state}ï¼Œä»–å€‘çš„å›ç­”æ­·å²å¦‚ä¸‹ï¼š{history}"},
        ]

        max_token_limit = 250  # ğŸ”¥ å…è®¸æ›´é•¿çš„è§£æ
    elif current_round >= MAX_ROUNDS:
        # **ç¬¬ N è¼ªå¾Œï¼Œç”Ÿæˆå®Œæ•´å¿ƒç†å­¸å ±å‘Š**
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½å¿ƒç†å­¸å°ˆå®¶ï¼Œè² è²¬å¹«åŠ©äººå€‘ç†è§£è‡ªå·±çš„æƒ…ç·’ã€‚"
                                          "è«‹æ ¹æ“šä½¿ç”¨è€…çš„å°è©±æ­·å²ï¼Œç”Ÿæˆä¸€ä»½ **å®Œæ•´çš„å¿ƒç†å­¸åˆ†æå ±å‘Š**ã€‚"
                                          "å ±å‘Šæ‡‰è©²åŒ…æ‹¬ï¼š\n"
                                          "1ï¸âƒ£ **æ ¸å¿ƒå•é¡Œåˆ†æ**ï¼šä½¿ç”¨è€…çš„æƒ…ç·’æ ¹æºå¯èƒ½æ˜¯ä»€éº¼ï¼Ÿ\n"
                                          "2ï¸âƒ£ **å¿ƒç†å½±éŸ¿**ï¼šé€™ç¨®æƒ…ç·’å¦‚ä½•å½±éŸ¿ä»–å€‘çš„è¡Œç‚ºã€æ±ºç­–ï¼Ÿ\n"
                                          "3ï¸âƒ£ **è§£æ±ºæ–¹æ¡ˆ**ï¼šæä¾› 2-3 å€‹å¯¦éš›å¯è¡Œçš„å»ºè­°ï¼Œå¹«åŠ©ä½¿ç”¨è€…æ”¹å–„æƒ…ç·’ã€‚\n"
                                          "è«‹ç¢ºä¿å ±å‘Šå…§å®¹æ¸…æ™°ã€å…·é«”ï¼Œ**ä¸è¶…é 250 å­—**ï¼Œä¸è¦ä½¿ç”¨éæ–¼å°ˆæ¥­çš„è¡“èªï¼Œè®“ä¸€èˆ¬äººèƒ½ç†è§£ã€‚"},
            {"role": "user", "content": f"ç•¶å‰ä½¿ç”¨è€…çš„æƒ…ç·’æ˜¯ {state}ï¼Œä»–å€‘çš„å›ç­”æ­·å²å¦‚ä¸‹ï¼š{history}"},
        ]

        max_token_limit = 250
    else:
        # **å‰ N è¼ª â†’ ç¹¼çºŒå•æ·±å…¥çš„å•é¡Œ**
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½å¿ƒç†å­¸å°ˆå®¶ï¼Œè² è²¬å¹«åŠ©äººå€‘æ·±å…¥ç†è§£è‡ªå·±çš„æƒ…ç·’ã€‚"
                                          "è«‹æ ¹æ“šä½¿ç”¨è€…çš„æƒ…ç·’èˆ‡éå»çš„å°è©±ï¼Œ**æå‡ºä¸€å€‹èƒ½è®“ä»–å€‘å›æ†¶ç«¥å¹´é™°å½±çš„å•é¡Œ**ã€‚"
                                          "è«‹ç¢ºä¿å•é¡Œ **ç›´æ¥ã€ç°¡çŸ­ã€ä¸è¶…é 50 å­—**ï¼Œ"
                                          "ä¸¦ä¸” **è®“ä½¿ç”¨è€…è¯æƒ³åˆ°ç«¥å¹´ç¶“æ­·**ã€‚**åªè¼¸å‡ºå•é¡Œï¼Œä¸æä¾›é¡å¤–èªªæ˜**ã€‚"},
            {"role": "user", "content": f"ç•¶å‰ä½¿ç”¨è€…çš„æƒ…ç·’æ˜¯ {state}ï¼Œä»–å€‘çš„å›ç­”æ­·å²å¦‚ä¸‹ï¼š{history}"},
        ]

        max_token_limit = 50

    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=messages,
        temperature=0.7,
        max_tokens=max_token_limit
    )

    return response.choices[0].message.content.strip()
def analyze_psychology_by_model(text: str, model: str = "distilbert", history: list = []):
    """é€é psychology_analysis API è™•ç†"""
    request = {
        "text": text,
        "model": model,
        "history": history
    }
    return psychology_analysis(request)