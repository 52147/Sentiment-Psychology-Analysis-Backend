from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from models import analyze_psychology
from adversarial import generate_adversarial_text, adversarial_attack_test
from openai import OpenAI
from typing import List, Optional
from pydantic import BaseModel
from transformers import pipeline
import openai
import os
import json  # âœ… ç¢ºä¿å°å…¥ JSON
import requests 
from dotenv import load_dotenv  # Install with: pip install python-dotenv


# ğŸ”¥ é—œé–‰ HuggingFace tokenizer ä¸¦è¡Œè™•ç†
os.environ["TOKENIZERS_PARALLELISM"] = "false"

load_dotenv()  # âœ… Load environment variables from .env file

# âœ… å¾ç’°å¢ƒè®Šæ•¸è®€å– API Key
api_key = os.getenv("OPENAI_API_KEY")  

client = OpenAI(api_key=api_key)

app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
def root():
    return {"message": "Sentiment & Psychology NLP API is running!"}


# âœ… **æ–°å¢å°è©±æ­·å²çš„å­˜å„²çµæ§‹**
conversation_history = {}  # å­˜å„²æ¯å€‹ç”¨æˆ¶çš„å°è©±æ­·å²ï¼ˆkey: user_id, value: historyï¼‰


class TextRequest(BaseModel):
    user_id: str
    text: str
    history: list = []
    deep_dive: bool = False
    attack_type: str = "none"  # âœ… é è¨­ç„¡å°æŠ—æ”»æ“Š
    model: str = "distilbert"  # âœ… é è¨­ NLP æ¨¡å‹

@app.post("/conversation")
def update_conversation(request: TextRequest):
    """æ›´æ–°å°è©±æ­·å²"""
    user_id = request.user_id
    if user_id not in conversation_history:
        conversation_history[user_id] = []
    
    conversation_history[user_id].append(request.text)
    return {"message": "Conversation updated", "history": conversation_history[user_id]}



# âœ… è¨­å®šå¯é¸æ“‡çš„ NLP æ¨¡å‹
# âœ… æ­£ç¢ºåˆå§‹åŒ– NLP pipelineï¼Œè€Œä¸æ˜¯å­˜å­—ä¸²
MODEL_MAPPING = {
    "roberta-large": pipeline("sentiment-analysis", model="cardiffnlp/twitter-roberta-base-emotion"),  # âœ… ä½¿ç”¨ Cardiff NLP ç‰ˆæœ¬
    "bert-base": pipeline("sentiment-analysis", model="nlptown/bert-base-multilingual-uncased-sentiment"),
    "xlm-roberta": pipeline("sentiment-analysis", model="cardiffnlp/twitter-xlm-roberta-base-sentiment"),
    "gpt-3.5-turbo": "gpt-3.5-turbo"  # âœ… é€™å€‹ç”¨ OpenAI API è™•ç†ï¼Œä¸è¦ç”¨ pipeline()
}


@app.post("/analyze_psychology")
def psychology_analysis(request: dict):
    """ä½¿ç”¨ GPT-3.5 Turbo æˆ– HuggingFace æ¨¡å‹é€²è¡Œå¿ƒç†åˆ†æ"""
    
    model_name = request.get("model", "distilbert")
    user_text = request.get("text", "").strip()
    history = request.get("history", [])

    if not user_text:
        raise HTTPException(status_code=400, detail="è«‹æä¾›æœ‰æ•ˆçš„æ–‡æœ¬")

    # âœ… **ä½¿ç”¨ GPT-3.5 Turbo é€²è¡Œæ·±åº¦å¿ƒç†åˆ†æ**
    if model_name == "gpt-3.5-turbo":
        prompt = f"""è«‹åˆ†æä»¥ä¸‹æ–‡æœ¬çš„å¿ƒç†ç‹€æ…‹ï¼Œä¸¦è¿”å› **JSON æ ¼å¼**ï¼š
        {{
            "state": "ä¸»è¦æƒ…ç·’",
            "confidence": 0-100,
            "emotion_scores": {{
                "Anxiety": 0-100,
                "Confidence": 0-100,
                "Overthinking": 0-100,
                "Self-Doubt": 0-100,
                "Social Avoidance": 0-100,
                "Aggression": 0-100
            }},
            "psychology_factors": {{
                "Anxiety": 0-100,
                "Confidence": 0-100,
                "Overthinking": 0-100,
                "Self-Doubt": 0-100,
                "Social Avoidance": 0-100,
                "Aggression": 0-100
            }},
            "next_question": "è«‹æ ¹æ“šé€™å€‹å¿ƒç†åˆ†æçµæœï¼Œæå‡ºä¸€å€‹è®“ä½¿ç”¨è€…æ·±å…¥æ¢ç´¢è‡ªèº«æƒ…ç·’çš„å•é¡Œ"
        }}
        ç¢ºä¿æ‰€æœ‰æ•¸å€¼ç¯„åœç‚º 0-100ï¼Œæ•¸å€¼è¶Šé«˜ä»£è¡¨è©²å¿ƒç†å› ç´ è¶Šå¼·çƒˆã€‚\n\n
        æ–‡æœ¬ï¼š{user_text}
        """

        try:
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
                max_tokens=300
            )
            analysis_result = json.loads(response.choices[0].message.content)

            return {
                "psychology_analysis": analysis_result,
                "next_question": analysis_result.get("next_question", "é€™å€‹åˆ†æçµæœå°ä½ çš„å½±éŸ¿æ˜¯ä»€éº¼ï¼Ÿ"),
                "model_used": "gpt-3.5-turbo"
            }
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"GPT-3.5 Turbo Error: {str(e)}")

    # âœ… **ä½¿ç”¨ Hugging Face æ¨¡å‹**
    if model_name in MODEL_MAPPING:
        try:
            nlp_pipeline = MODEL_MAPPING[model_name]
            analysis = nlp_pipeline(user_text)  # ç²å–åˆ†é¡çµæœ
            
            # **ç¢ºä¿åˆ†æçµæœæ˜¯ JSON æ ¼å¼**
            if isinstance(analysis, list) and isinstance(analysis[0], dict):
                emotion_scores = {entry["label"]: round(entry["score"] * 100, 1) for entry in analysis}

                # âœ… è½‰æ›ç‚º `psychology_factors` æ ¼å¼
                psychology_factors = {}
                if model_name == "bert-base":
                    psychology_factors = {
                        "Anxiety": emotion_scores.get("1 star", 0) + emotion_scores.get("2 stars", 0),
                        "Confidence": max(emotion_scores.get("4 stars", 0) + emotion_scores.get("5 stars", 0), 50),
                        "Overthinking": emotion_scores.get("1 star", 0),
                        "Self-Doubt": emotion_scores.get("2 stars", 0),
                        "Social Avoidance": emotion_scores.get("1 star", 0),
                        "Aggression": emotion_scores.get("1 star", 0) + emotion_scores.get("2 stars", 0)
                    }
                else:
                    psychology_factors = {
                        "Anxiety": emotion_scores.get("fear", 0) + emotion_scores.get("sadness", 0),
                        "Confidence": max(emotion_scores.get("joy", 0), 50),  # è¨­å®š Confidence é è¨­å€¼
                        "Overthinking": emotion_scores.get("fear", 0),
                        "Self-Doubt": emotion_scores.get("anger", 0),
                        "Social Avoidance": emotion_scores.get("sadness", 0) + emotion_scores.get("fear", 0),
                        "Aggression": emotion_scores.get("anger", 0)
                    }

                # âœ… é¸å–ä¸»è¦å¿ƒç†ç‹€æ…‹
                primary_state = max(psychology_factors, key=psychology_factors.get)

                # âœ… ğŸ”¥ **é€™è£¡æ–°å¢ GPT ä¾†ç”Ÿæˆ next_question**
                next_q = generate_next_question(primary_state, emotion_scores, history)

                return {
                    "psychology_analysis": {
                        "state": primary_state,
                        "confidence": psychology_factors[primary_state],
                        "emotion_scores": emotion_scores,
                        "psychology_factors": psychology_factors
                    },
                    "next_question": next_q,  # âœ… **é€™è£¡çš„ next_question æ˜¯ GPT ç”Ÿæˆçš„**
                    "model_used": model_name
                }
            else:
                raise HTTPException(status_code=500, detail="æ¨¡å‹è¿”å›çš„æ•¸æ“šæ ¼å¼ç„¡æ³•è§£æ")
        
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"æ¨¡å‹åŸ·è¡ŒéŒ¯èª¤: {str(e)}")

    return {"error": "è«‹é¸æ“‡æœ‰æ•ˆçš„ NLP æ¨¡å‹"}

@app.post("/generate_question")
def generate_next_question(state: str, history: list, deep_dive: bool = False):
    """
    ç”Ÿæˆå¿ƒç†å­¸å•é¡Œï¼š
    - **ä¸€èˆ¬æ¨¡å¼**ï¼šè©¢å•ä½¿ç”¨è€…æƒ…ç·’ï¼ŒæŒ–æ˜ç«¥å¹´é™°å½±
    - **æ·±å…¥æ¨¡å¼**ï¼šåˆ†æã€Œç‚ºä»€éº¼å°æ–¹é€™æ¨£å°ä½ ï¼Ÿã€ä¸¦æä¾›è¡Œå‹•æ–¹æ¡ˆ
    """
    MAX_ROUNDS = 3
    current_round = len(history)

    if deep_dive:
        # **ğŸ”¥ æ·±å…¥æ¨¡å¼ â†’ è§£æè¡Œç‚ºå‹•æ©Ÿ**
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½å¿ƒç†å­¸å°ˆå®¶ï¼Œæ“…é•·åˆ†æå®¶åº­é—œä¿‚èˆ‡ä»£éš›å‰µå‚·ã€‚"
                                          "è«‹æ ¹æ“šä½¿ç”¨è€…çš„ç¶“æ­·ï¼Œå›ç­”ï¼š**ç‚ºä»€éº¼å°æ–¹æœƒé€™æ¨£å°å¾…ä»–ï¼Ÿ**\n\n"
                                          "ğŸ“Œ **åˆ†æå…§å®¹æ‡‰åŒ…æ‹¬ï¼š**\n"
                                          "1ï¸âƒ£ **å¿ƒç†æ©Ÿåˆ¶ï¼ˆreasonï¼‰**ï¼šå°æ–¹è¡Œç‚ºçš„çœŸæ­£åŸå› ã€‚\n"
                                          "2ï¸âƒ£ **æƒ…ç·’å½±éŸ¿ï¼ˆimpactï¼‰**ï¼šé€™ç¨®è¡Œç‚ºå¦‚ä½•å½±éŸ¿ä½¿ç”¨è€…ã€‚\n"
                                          "3ï¸âƒ£ **è¡Œå‹•æ–¹æ¡ˆï¼ˆadviceï¼‰**ï¼šæä¾› 2-3 å€‹å¯¦éš›å»ºè­°ï¼Œå¹«åŠ©ä½¿ç”¨è€…æ“ºè„«é€™ç¨®å½±éŸ¿ã€‚\n\n"
                                          "âš ï¸ **è«‹æä¾› JSON æ ¼å¼çš„è¼¸å‡ºï¼Œä¸è¦ä½¿ç”¨ Markdownã€‚**"},
            {"role": "user", "content": f"ç•¶å‰ä½¿ç”¨è€…çš„æƒ…ç·’æ˜¯ {state}ï¼Œä»–å€‘çš„å›ç­”æ­·å²å¦‚ä¸‹ï¼š{history}"},
        ]
        max_token_limit = 300

        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=messages,
            temperature=0.7,
            max_tokens=max_token_limit
        )

        # **âœ… å˜—è©¦è§£æ JSON**
        try:
            deep_dive_analysis = json.loads(response.choices[0].message.content)
        except json.JSONDecodeError:
            deep_dive_analysis = {"error": "GPT è¿”å›çš„ JSON ç„¡æ³•è§£æ", "raw_content": response.choices[0].message.content}

        return deep_dive_analysis  # **âœ… é€™è£¡æ‡‰è©²å›å‚³å®Œæ•´çš„ JSONï¼Œè€Œä¸æ˜¯ `next_question`**

    # **ğŸ”¥ ç¬¬ 3 è¼ªå¾Œ â†’ ç”Ÿæˆå®Œæ•´å¿ƒç†å­¸å ±å‘Š**
    elif current_round >= MAX_ROUNDS:
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½å¿ƒç†å­¸å°ˆå®¶ï¼Œè«‹æ ¹æ“šä½¿ç”¨è€…çš„å°è©±æ­·å²ï¼Œ"
                                          "ç”Ÿæˆä¸€ä»½ **å®Œæ•´çš„å¿ƒç†å­¸åˆ†æå ±å‘Š**ã€‚\n\n"
                                          "ğŸ“Œ **å ±å‘Šæ‡‰åŒ…æ‹¬ï¼š**\n"
                                          "1ï¸âƒ£ **æ ¸å¿ƒå•é¡Œåˆ†æ**ï¼šä½¿ç”¨è€…çš„æƒ…ç·’æ ¹æºå¯èƒ½æ˜¯ä»€éº¼ï¼Ÿ\n"
                                          "2ï¸âƒ£ **å¿ƒç†å½±éŸ¿**ï¼šé€™ç¨®æƒ…ç·’å¦‚ä½•å½±éŸ¿ä»–å€‘çš„è¡Œç‚ºï¼Ÿ\n"
                                          "3ï¸âƒ£ **è§£æ±ºæ–¹æ¡ˆ**ï¼šæä¾› 2-3 å€‹å¯¦éš›å»ºè­°ä¾†æ”¹å–„æƒ…ç·’ã€‚\n\n"
                                          "âš ï¸ **è«‹ç¢ºä¿å ±å‘Šæ¸…æ™°ã€å…·é«”ï¼Œä¸è¶…é 300 å­—ï¼Œä¸¦é¿å…ä½¿ç”¨å°ˆæ¥­è¡“èªã€‚**"},
            {"role": "user", "content": f"ç•¶å‰ä½¿ç”¨è€…çš„æƒ…ç·’æ˜¯ {state}ï¼Œä»–å€‘çš„å›ç­”æ­·å²å¦‚ä¸‹ï¼š{history}"},
        ]
        max_token_limit = 300

    else:
        # **ğŸ”¥ å‰ 3 è¼ª â†’ ç¹¼çºŒæŒ–æ˜ç«¥å¹´é™°å½±**
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½å¿ƒç†å­¸å°ˆå®¶ï¼Œè² è²¬å¹«åŠ©äººå€‘æ·±å…¥ç†è§£è‡ªå·±çš„æƒ…ç·’ã€‚"
                                          "è«‹æ ¹æ“šä½¿ç”¨è€…çš„æƒ…ç·’èˆ‡éå»çš„å°è©±ï¼Œ**æå‡ºä¸€å€‹èƒ½è®“ä»–å€‘å›æ†¶ç«¥å¹´é™°å½±çš„å•é¡Œ**ã€‚"
                                          "è«‹ç¢ºä¿å•é¡Œ **ç›´æ¥ã€ç°¡çŸ­ã€ä¸è¶…é 50 å­—**ï¼Œä¸¦ä¸” **è®“ä½¿ç”¨è€…è¯æƒ³åˆ°ç«¥å¹´ç¶“æ­·**ã€‚"
                                          "**åªè¼¸å‡ºå•é¡Œï¼Œä¸æä¾›é¡å¤–èªªæ˜**ã€‚"},
            {"role": "user", "content": f"ç•¶å‰ä½¿ç”¨è€…çš„æƒ…ç·’æ˜¯ {state}ï¼Œä»–å€‘çš„å›ç­”æ­·å²å¦‚ä¸‹ï¼š{history}"},
        ]
        max_token_limit = 50

    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=messages,
        temperature=0.7,
        max_tokens=max_token_limit
    )

    return response.choices[0].message.content.strip()

class AttackRequest(BaseModel):
    text: str
    attack_type: str = "synonym"
    model: str = "distilbert"  # âœ… æ–°å¢ NLP æ¨¡å‹é¸æ“‡åƒæ•¸

@app.post("/adversarial_attack")
def adversarial_test(request: AttackRequest):
    try:
        adversarial_text = generate_adversarial_text(request.text, request.attack_type)

        original_analysis = simple_psychology_analysis({"text": request.text, "model": request.model})
        adversarial_analysis = (
            simple_psychology_analysis({"text": adversarial_text, "model": request.model})
            if adversarial_text != request.text
            else original_analysis
        )

        return {
            "original_text": request.text,
            "adversarial_text": adversarial_text,
            "original_analysis": original_analysis,
            "adversarial_analysis": adversarial_analysis
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error processing adversarial attack: {str(e)}")
    

# åœ¨ simple_psychology_analysis API å…§éƒ¨
@app.post("/simple_psychology_analysis")
def simple_psychology_analysis(request: dict):
    model_name = request.get("model", "distilbert")
    user_text = request.get("text", "").strip()

    if not user_text:
        raise HTTPException(status_code=400, detail="è«‹æä¾›æœ‰æ•ˆçš„æ–‡æœ¬")

    if model_name == "gpt-3.5-turbo":
        prompt = f"""è«‹åˆ†æä»¥ä¸‹æ–‡æœ¬çš„å¿ƒç†ç‹€æ…‹ï¼Œä¸¦è¿”å› JSON æ ¼å¼ï¼š
        {{
            "state": "ä¸»è¦æƒ…ç·’",
            "confidence": 0-100,
            "emotion_scores": {{
                "Anxiety": 0-100,
                "Confidence": 0-100,
                "Overthinking": 0-100,
                "Self-Doubt": 0-100,
                "Social Avoidance": 0-100,
                "Aggression": 0-100
            }},
            "psychology_factors": {{
                "Anxiety": 0-100,
                "Confidence": 0-100,
                "Overthinking": 0-100,
                "Self-Doubt": 0-100,
                "Social Avoidance": 0-100,
                "Aggression": 0-100
            }}
        }}
        æ–‡æœ¬ï¼š{user_text}
        """

        try:
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
                max_tokens=300
            )
            analysis_result = json.loads(response.choices[0].message.content)

            return {
                "state": analysis_result["state"],
                "confidence": analysis_result["confidence"],
                "emotion_scores": analysis_result["emotion_scores"],
                "psychology_factors": analysis_result["psychology_factors"],
                "model_used": "gpt-3.5-turbo"
            }
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"GPT-3.5 Turbo Error: {str(e)}")

    elif model_name in MODEL_MAPPING:
        try:
            nlp_pipeline = MODEL_MAPPING[model_name]
            analysis = nlp_pipeline(user_text)
            
            emotion_scores = {entry["label"]: round(entry["score"] * 100, 1) for entry in analysis}

            psychology_factors = {}
            
            if model_name == "xlm-roberta":
                psychology_factors = {
                    "Anxiety": emotion_scores.get("negative", 0),
                    "Confidence": max(emotion_scores.get("positive", 0), 50),
                    "Overthinking": emotion_scores.get("negative", 0),
                    "Self-Doubt": emotion_scores.get("negative", 0),
                    "Social Avoidance": emotion_scores.get("negative", 0),
                    "Aggression": emotion_scores.get("negative", 0),
                }
            elif model_name == "bert-base":
                psychology_factors = {
                    "Anxiety": emotion_scores.get("1 star", 0) + emotion_scores.get("2 stars", 0),
                    "Confidence": max(emotion_scores.get("4 stars", 0) + emotion_scores.get("5 stars", 0), 50),
                    "Overthinking": emotion_scores.get("1 star", 0),
                    "Self-Doubt": emotion_scores.get("2 stars", 0),
                    "Social Avoidance": emotion_scores.get("1 star", 0),
                    "Aggression": emotion_scores.get("1 star", 0) + emotion_scores.get("2 stars", 0)
                }
            else:
                psychology_factors = {
                    "Anxiety": emotion_scores.get("fear", 0) + emotion_scores.get("sadness", 0),
                    "Confidence": max(emotion_scores.get("joy", 0), 50),
                    "Overthinking": emotion_scores.get("fear", 0),
                    "Self-Doubt": emotion_scores.get("anger", 0),
                    "Social Avoidance": emotion_scores.get("sadness", 0) + emotion_scores.get("fear", 0),
                    "Aggression": emotion_scores.get("anger", 0)
                }

            primary_state = max(psychology_factors, key=psychology_factors.get)

            return {
                "state": primary_state,
                "confidence": psychology_factors[primary_state],
                "emotion_scores": emotion_scores,
                "psychology_factors": psychology_factors,
                "model_used": model_name
            }
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"æ¨¡å‹åŸ·è¡ŒéŒ¯èª¤: {str(e)}")

    raise HTTPException(status_code=400, detail="è«‹é¸æ“‡æœ‰æ•ˆçš„ NLP æ¨¡å‹")