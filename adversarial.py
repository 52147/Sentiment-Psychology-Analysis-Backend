import os
import random
from openai import OpenAI
from dotenv import load_dotenv  # Install with: pip install python-dotenv

import jieba  # âœ… Import jieba for Chinese text segmentation
load_dotenv()  # âœ… Load environment variables from .env file
# âœ… å¾ç’°å¢ƒè®Šæ•¸è®€å– API Key
api_key = os.getenv("OPENAI_API_KEY")  
client = OpenAI(api_key=api_key)

def generate_adversarial_text(text: str, attack_type: str = "synonym"):
    """ç”¨ GPT ç”Ÿæˆæ›´å¼·çš„å°æŠ—æ¨£æœ¬"""
    
    if attack_type == "synonym":
        # ğŸ”¥ è®“ GPT ç”Ÿæˆèªç¾©ç›¸ä¼¼ä½†ä¸åŒè¡¨é”çš„å¥å­
        prompt = f"è«‹æ”¹å¯«ä»¥ä¸‹å¥å­ï¼Œä½¿å…¶æ„æ€ç›¸åŒä½†ç”¨ä¸åŒçš„è¡¨é”æ–¹å¼ï¼š\n{text}"
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
            max_tokens=50
        )
        return response.choices[0].message.content.strip()
    
    
    elif attack_type == "swap":
        words = list(jieba.cut(text))  # âœ… Use jieba to split words correctly
        if len(words) > 1:
            idx1, idx2 = random.sample(range(len(words)), 2)  # Pick 2 different word positions
            words[idx1], words[idx2] = words[idx2], words[idx1]  # Swap them

        return "".join(words)  # âœ… Join back into a full sentence
    
    elif attack_type == "contextual":
        # ğŸ”¥ GPT ç”Ÿæˆä¸€å€‹ã€Œæ›´å¼·çƒˆçš„ã€èªå¢ƒè®ŠåŒ–ç‰ˆæœ¬
        prompt = (
            f"è«‹å°‡ä»¥ä¸‹å¥å­é‡æ–°è¡¨é”ï¼Œä¸¦æ”¹è®Šå…¶èƒŒæ™¯æˆ–æƒ…å¢ƒï¼Œä½¿å…¶æƒ…ç·’æ›´åŠ å¼·çƒˆæˆ–æ¥µç«¯ï¼Œä½†ä»ç„¶ä¿æŒå¯è®€æ€§ï¼š\n{text}"
        )
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=1.0,  # ğŸ”¥ æé«˜å‰µé€ åŠ›
            max_tokens=100  # âœ… è®“å›æ‡‰æ›´å®Œæ•´
        )
        return response.choices[0].message.content.strip()
    
    else:
        return "âš ï¸ ç„¡æ•ˆçš„æ”»æ“Šé¡å‹"
    


def adversarial_attack_test(text: str, attack_type: str = "synonym"):
    """Generates adversarial examples to test AI robustness."""

    if attack_type == "synonym":
        # ğŸ”¥ Generate a semantically similar sentence
        prompt = f"è«‹æ”¹å¯«ä»¥ä¸‹å¥å­ï¼Œä½¿å…¶æ„æ€ç›¸åŒä½†ç”¨ä¸åŒçš„è¡¨é”æ–¹å¼ï¼š\n{text}"
        try:
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
                max_tokens=50
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            return f"âŒ OpenAI API Error: {str(e)}"

    elif attack_type == "swap":
        words = list(jieba.cut(text))  # âœ… Ensure text is split properly
        if len(words) > 1:
            idx1, idx2 = random.sample(range(len(words)), 2)  # Pick two positions
            words[idx1], words[idx2] = words[idx2], words[idx1]  # Swap words
            swapped_text = "".join(words)
            
            # Ensure swap actually changes something
            if swapped_text == text:
                return "âš ï¸ Swap attack failed: No change in text."
            
            return swapped_text
        return "âš ï¸ Text too short to swap."

    elif attack_type == "contextual":
        # ğŸ”¥ Make sentence more extreme or emotionally strong
        prompt = f"è«‹åŠ å¼·ä»¥ä¸‹å¥å­çš„æƒ…ç·’ï¼Œä½¿å…¶æ›´åŠ æ¥µç«¯æˆ–èª‡å¼µï¼š\n{text}"
        try:
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                temperature=1.0,
                max_tokens=100
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            return f"âŒ OpenAI API Error: {str(e)}"

    else:
        return "âš ï¸ Invalid attack type."